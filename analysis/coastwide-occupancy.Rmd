---
title: "Coastwide sand lance model"
author: "Philina English"
date: "`r Sys.Date()`"
output: html_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(
  fig.width = 11, fig.height = 8.5,
  # fig.path=paste0("figs/", spp, "/"),
  echo = TRUE, warning = FALSE, message = FALSE
)
library(here)
library(readr)
library(tidyverse)
# library(gfdata)
library(sdmTMB)

theme_set(
    ggsidekick::theme_sleek(base_size = 14) 
)
```

```{r get-data}
.d <- read_csv(here("data/PSL_survey_sets_with_covariates.csv"))
# d2 <- read_csv(here("data/Bycatch_with_covariates.csv"))
# glimpse(d)
# glimpse(d2)
```



Sand lance data from trawl surveys suffers from sometimes being recorded as counts and sometimes as weights. Use simple linear regression to fill in an estimated biomass for count only values. However, it may be safer to just use presence absence instead.

```{r}

# # calculate area_swept incase we wish to use an offset
# # note: the conversion from count to biomass will also need redoing for to use this
# .d$area_swept1 <- .d$doorspread_m * .d$tow_length_m
# .d$area_swept2 <- .d$doorspread_m * (.d$speed_mpm * .d$duration_min)
# .d$area_swept <- ifelse(!is.na(.d$area_swept1), .d$area_swept1, .d$area_swept2)


# first remove all false 0s in dataframe
.d$catch_count <- ifelse(.d$catch_weight > 0 & .d$catch_count == 0, NA, .d$catch_count)
.d$catch_weight <- ifelse(.d$catch_count > 0 & .d$catch_weight == 0, NA, .d$catch_weight)
.d$density_pcpm2 <- ifelse(.d$catch_weight > 0 & .d$density_pcpm2 == 0, NA, .d$density_pcpm2)
.d$density_kgpm2 <- ifelse(.d$catch_count > 0 & .d$density_kgpm2 == 0, NA, .d$density_kgpm2)

# create presence-absence variable and make density units per km2 instead of m2
.d$present <- ifelse(.d$density_pcpm2 > 0|.d$density_kgpm2 > 0, 1, 0)

d2 <- .d %>% #filter(present == 1) %>% 
  mutate(density_kgkm2 = density_kgpm2*1000000,
         density_pckm2 = density_pcpm2*1000000
         )
# generate simple linear model formula
f <- lm(density_kgkm2~density_pckm2, data = d2)

# fill in missing biomass densities
d2$density_filled <- ifelse(is.na(d2$density_kgkm2), 
                            d2$density_pckm2*f$coefficients[2] + f$coefficients[1],
                            d2$density_kgkm2)
```

Plot the filled in estimates of biomass density for samples that only had counts in red. 

```{r warning=FALSE}
d2 %>% filter(density_pckm2 > 0) %>% 
ggplot(aes(density_pckm2, density_kgkm2)) + 
  geom_point(aes(density_pckm2, density_filled), colour = "red") + 
    geom_point(colour = "black") 
```

Plot these biomass density against bathymetry
```{r}
d2 %>% filter(present == 1) %>%
ggplot(aes(-Bathy_mean, density_filled)) + 
  geom_point(colour = "red") + 
  geom_point(aes(-Bathy_mean, density_kgkm2), colour = "black")
```


Plot these biomass density against measured depth of the tow
```{r}
d2 %>% filter(present == 1) %>%
ggplot(aes(depth_m, density_filled)) + 
  geom_point(colour = "red") + 
  geom_point(aes(depth_m, density_kgkm2), colour = "black")
```

Compare bathymetry to measured depth
```{r}
d2 %>% filter(present == 1) %>%
ggplot(aes(depth_m, -Bathy_mean)) + 
  geom_point(colour = "red") + 
  geom_point(aes(depth_m, -Bathy_mean ), colour = "black", alpha = 0.5)
```

Simplify dataframe
```{r}
d3 <- d2 %>% select(lon_centroid, lat_centroid, survey_abbrev, year, month, day, time_deployed, 
                    depth_m, fishing_event_id, present, density_filled, 39:ncol(d2))

d4 <- d3[!is.na(d3$lon_centroid),]

d  <- add_utm_columns(d4, ll_names =c("lon_centroid", "lat_centroid"), utm_crs = 32609)
d$log_depth <- log(-d$Bathy_mean)
```


Way too many variables! 
I investigated correlations to help choose with variables to consider, but this wasn't a good way to go. 
Need a better strategy.

```{r}
library("PerformanceAnalytics")
# my_data1 <- d[, 11:22]
# chart.Correlation(my_data1, histogram=TRUE, pch=19)
# 
# my_data2 <- d[, c(11, 23:30) ]
# chart.Correlation(my_data2, histogram=TRUE, pch=19)
# 
my_data3 <- d[, c(11, 12, 18, 24, 66, 72, 84, 91, 106, 108, 120, 125, 141) ]
chart.Correlation(my_data3, histogram=TRUE, pch=19)
```

Temperature correlations
```{r}
plot(TeSmr_max~TeMin_mean, data= d)
plot(TeSmr_mean~TeWnt_mean, data= d)
plot(TeMax_mean~TeMin_mean, data= d)
plot(TeMin_mean~TeWnt_mean, data= d)

plot(TeMin_mean~log_depth, data= d)
plot(TeWnt_mean~log_depth, data= d)
```

Tidal speed correlations
```{r}

plot(TiMax_mean~TiMin_mean, data= d)
plot(TiMax_mean~TiWnt_mean, data= d)
plot(TiMax_mean~TiSmr_mean, data= d)
```

Bottom terrain correlations

```{r}
plot(density_filled~TRIx_max, data= d)
plot(density_filled~FiBPI_mean, data= d)
plot(density_filled~BrBPI_mean, data= d)
plot(density_filled~Slope_mean, data= d)

plot(BrBPI_mean~Slope_mean, data= d)
plot(Grain_mean~Slope_mean, data= d)
```

Grain size and distance to estuary

```{r}
plot(density_filled~DisEs_mean, data= d)
plot(density_filled~Grain_mean, data= d)
plot(density_filled~Grain_std, data= d)
plot(Grain_mean~Grain_std, data= d)
```

Sand lance were only caught for these surveys: SYN QCS, HS MSA, SYN HS and SYN WCVI. Remove the rest.

```{r}
# unique(d$survey_abbrev)
d <- filter(d, survey_abbrev %in% c("SYN QCS","HS MSA","SYN HS","SYN WCVI"))
```

Need to get rid of NAs in any variables you intend to use.
```{r echo=FALSE}
d <- d %>% select(X, Y, lon_centroid, lat_centroid, survey_abbrev, year, month, day, time_deployed,
                  fishing_event_id, present, density_filled,
                  depth_m, Bathy_mean, log_depth, 
                  BrBPI_mean, Slope_mean, 
                  Grain_mean, Grain_std,
                  TiMax_mean, # tidal current - flushing of silt and mixing for prey production
                  TeMin_mean # min temperature to represent winter conditions and risk of being too warm
                  )
d <- na.omit(d)
```


Plot raw data to see what survey areas are represented in which years.
```{r}
ggplot() + 
  geom_point(aes(X, Y), data = d, alpha = 0.2, size = 0.5)+
  geom_point(aes(X, Y), data = filter(d, present ==1), colour = "red", size = 0.5) +
  facet_wrap(~year)
```
Due to alternating year survey design, one option is to pair years. 
```{r}
d <- d %>% filter(year > 1992) %>% mutate(
      year_scaled = (year - 2010)/10,
      year_pair = case_when(
        year %in% c(1993, 1994) ~ 1993,
        year %in% c(1995, 1996) ~ 1995,
        year %in% c(1997, 1998) ~ 1997,
        year %in% c(1999, 2000) ~ 1999,
        year %in% c(2001, 2002) ~ 2001,
        year %in% c(2003, 2004) ~ 2003,
        year %in% c(2005, 2006) ~ 2005,
        year %in% c(2007, 2008) ~ 2007,
        year %in% c(2009, 2010) ~ 2009,
        year %in% c(2011, 2012) ~ 2011,
        year %in% c(2013, 2014) ~ 2013,
        year %in% c(2015, 2016) ~ 2015,
        year %in% c(2017, 2018) ~ 2017,
        year %in% c(2019, 2020) ~ 2019,# no WCVI
        year %in% c(2021, 2022) ~ 2021   
      ),
      year_true = year)
```


Odd year data is pooled with subsequent even year, but more data is available in odd years so that's how they are labeled. 

```{r}
ggplot() + 
  geom_point(aes(X, Y), data = d, alpha = 0.2, size = 0.5)+
  geom_point(aes(X, Y), data = filter(d, present ==1), colour = "red", size = 0.5) +
  facet_wrap(~year_pair)
```
Create meshes of a few different resolutions to see what works better.
Bigger cutoff = coarser mesh = faster model. 
As long as the mesh isn't too coarse, in which case the model will struggle. 

```{r}
mesh10 <- make_mesh(d, xy_cols = c("X", "Y"), cutoff = 10)
ggplot() + inlabru::gg(mesh10$mesh) + coord_fixed() +
  geom_point(aes(X, Y), data = d, alpha = 0.2, size = 0.5)+
  geom_point(aes(X, Y), data = filter(d, present ==1), colour = "red", size = 0.5)
```

```{r}
mesh5 <- make_mesh(d, xy_cols = c("X", "Y"), cutoff = 5)
ggplot() + inlabru::gg(mesh5$mesh) + coord_fixed() +
  geom_point(aes(X, Y), data = d, alpha = 0.2, size = 0.5)+
  geom_point(aes(X, Y), data = filter(d, present ==1), colour = "red", size = 0.5)
```

```{r}
mesh8 <- make_mesh(d, xy_cols = c("X", "Y"), cutoff = 8)
ggplot() + inlabru::gg(mesh8$mesh) + coord_fixed() +
  geom_point(aes(X, Y), data = d, alpha = 0.2, size = 0.5)+
  geom_point(aes(X, Y), data = filter(d, present ==1), colour = "red", size = 0.5)
```

```{r}
mesh <- mesh8
```


### Why are there some negative grain sizes?!
```{r}
hist(d$Grain_mean)
```


The most efficient way to model this relatively sparse data may be using a spatial model with spatially-varying trends.
This is most easier to estimate than a fully spatiotemporal model. 
I tried a bunch of gamms/smoothers, but most variables seemed pretty linear in their effects. 

First I start with a presense-absence model:

```{r}
msv <- sdmTMB(present ~ 
                year_scaled +
                poly(BrBPI_mean, 2) + 
                poly(Slope_mean, 2) + 
                poly(Grain_mean, 2) +
                poly(Grain_std, 2) +
                poly(TiMax_mean, 2) +# tidal current - flushing of silt and mixing for prey production
                poly(TeMin_mean, 2) + # min temperature to represent winter conditions and risk of being too warm
                # BrBPI_mean + 
                # Slope_mean + 
                # Grain_mean + 
                # Grain_std +
                # TiMax_mean +# tidal current - flushing of silt and mixing for prey production
                # TeMin_mean + # min temperature to represent winter conditions and risk of being too warm
                log_depth,
                # s(log_depth, k = 3),
             spatial = TRUE,
             time = "year",
             spatial_varying = ~ 0 + year_scaled,
             spatiotemporal = "off",
             # share_range = FALSE,
             # anisotropy = TRUE,
             family = binomial(),
             mesh = mesh,
             data = d
)
```


Check fit?
If you have smoothers on variables that it can't estimate any curve for, the following with throw a red 'x' and a message about ln_smooth_sigma. 

```{r message=TRUE}
sanity(msv)
```

Print model:
```{r}
# msv <- run_extra_optimization(msv)
msv
# plot_anisotropy(msv) # if anisotropy = TRUE
```

Try a hurdle model for density: has a bionomial presense-absence component and a gamma component for abundance where present.

grain s
warmer winter(NOV-JAN) seabed reduces condition - TeMin_mean

```{r}
mdg <- sdmTMB(density_filled ~ 
                year_scaled +
                poly(BrBPI_mean, 2) + 
                poly(Slope_mean, 2) + 
                poly(Grain_mean, 2) +
                poly(Grain_std, 2) +
                poly(TiMax_mean, 2) + # tidal current - flushing of silt and mixing for prey production
                poly(TeMin_mean, 2) + # min temperature to represent winter conditions and risk of being too warm
                log(depth_m),
             spatial = TRUE,
             # anisotropy = TRUE,
             time = "year",
             spatial_varying = ~ 0 + year_scaled,
             spatiotemporal = "off",
             family = delta_gamma(),
             mesh = mesh,
             data = d
)
```

```{r}
sanity(mdg)
```

```{r}
mdg
```

```{r}
# plot_anisotropy(mdg)
```



```{r}
mdg2 <- sdmTMB(
  list(
    density_filled ~ 
      year_scaled + 
      poly(BrBPI_mean, 2) +  
      poly(Grain_mean, 2) + 
      Grain_std + 
      TiMax_mean + 
      poly(TeMin_mean, 2) + 
      log(depth_m),
    density_filled ~ 
      year_scaled + 
      BrBPI_mean +  
      Grain_mean + 
      Grain_std + 
      TiMax_mean + 
      poly(TeMin_mean, 2) + 
      log(depth_m)
),
             spatial = TRUE,
             # anisotropy = TRUE,
             time = "year",
             spatial_varying = ~ 0 + year_scaled,
             spatiotemporal = "off",
             family = delta_gamma(),
             mesh = mesh,
             data = d
)
```

```{r}
sanity(mdg2)
```
```{r}
mdg2
```

```{r}
# plot_anisotropy(mdg2)
```

Check tweedie, but Delta-gamma is way better
```{r}
# mtw <- update(mdg, family = tweedie())
# 
# AIC(mtw, mdg)
```

```{r}
visreg_delta(mdg2, "BrBPI_mean", scale= "response", model = 1)
visreg_delta(mdg2, "BrBPI_mean", scale= "response", model = 2)
```

```{r}
visreg_delta(mdg2, "Grain_mean", scale= "response", model = 1)
visreg_delta(mdg2, "Grain_mean", scale= "response", model = 2) 
```
```{r}
visreg_delta(mdg2, "Grain_std", scale= "response", model = 1)
visreg_delta(mdg2, "Grain_std", scale= "response", model = 2) 
```

```{r}
visreg_delta(mdg2, "TiMax_mean", scale= "response", model = 1)
visreg_delta(mdg2, "TiMax_mean", scale= "response", model = 2)
```

```{r}
visreg_delta(mdg2, "TeMin_mean", scale= "response", model = 1)
visreg_delta(mdg2, "TeMin_mean", scale= "response", model = 2)
```

```{r}
visreg_delta(mdg2, "depth_m", scale= "response", model = 1)
visreg_delta(mdg2, "depth_m", scale= "response", model = 2)
```


```{r eval=FALSE}
mdg2 <- sdmTMB(density_filled ~ 
                year_scaled +
                poly(Grain_mean, 2) +
                log_depth,
             spatial = TRUE,
             anisotropy = TRUE,
             time = "year",
             # spatial_varying = ~ 0 + year_scaled,
             spatiotemporal = "iid",
             family = delta_gamma(),
             mesh = mesh10,
             data = d
)
```

